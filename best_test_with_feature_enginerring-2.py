# -*- coding: utf-8 -*-
"""best test with feature enginerring.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rhSgxKk7gwtz6UfwEjRuBXeTihR2hjT-
"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

df_train = pd.read_csv('train.csv')

df_train

df_train.sort_values(by = 'GrLivArea', ascending = False)[:2]
df_train=df_train.drop(df_train[df_train['Id']==1299].index)
df_train=df_train.drop(df_train[df_train['Id']==524].index)

df_train.sort_values(by='TotalBsmtSF',ascending=False)[:2]
#df_train.drop(df_train[df_train['Id']==333].index,inplace=True)
df_train[df_train['TotalBsmtSF']>2000].sort_values(by='SalePrice',ascending=True)[:2]
df_train.drop(df_train[df_train['Id']==1224].index,inplace=True)

df_train.drop(df_train[(df_train.OverallQual==4) & (df_train.SalePrice>200000)].index,inplace=True)

df_train.drop(df_train[df_train['LotFrontage'] > 200].index,inplace=True)

df_train.drop(df_train[(df_train.YearBuilt < 1900) & (df_train.SalePrice > 200000)].index,inplace=True)
df_train.drop(df_train[(df_train.YearBuilt < 2000) & (df_train.SalePrice > 650000)].index,inplace=True)

import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression

test_data = pd.read_csv('test.csv')
# Define headers
# Define headers
Numerical_Headers =  [ 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',  'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']
Categorical_Headers = ['MSZoning', 'Street',  'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive',   'SaleType', 'SaleCondition']
# Separating features and labels

# Log transformation of the target variable
df_train['SalePrice'] = np.log(df_train['SalePrice'])

# Separate features and labels
train_data_label = df_train['SalePrice']
train_data_features = df_train.drop(['Id', 'SalePrice','Alley','GarageYrBlt','PoolQC','Fence','MiscFeature'], axis=1)
test_data_features = test_data.drop(['Id','Alley','GarageYrBlt','PoolQC','Fence','MiscFeature'], axis=1)

# Convert categorical headers to string
for column in Categorical_Headers:
    train_data_features[column] = train_data_features[column].astype(str)
    test_data_features[column] = test_data_features[column].astype(str)

# Define preprocessing for numerical and categorical data
num_processor = Pipeline([
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', MinMaxScaler(feature_range=(0, 1)))
])

cat_processor = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(sparse_output=True, handle_unknown='ignore'))
])

# Combine preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('num', num_processor, Numerical_Headers),
        ('cat', cat_processor, Categorical_Headers)
    ]
)

# Apply preprocessing
preprocessor.fit(train_data_features)
binary_train_data_features = preprocessor.transform(train_data_features)
binary_test_data_features = preprocessor.transform(test_data_features)

from sklearn.linear_model import Lasso
from sklearn.model_selection import RandomizedSearchCV
import numpy as np
import pandas as pd
from sklearn.metrics import mean_squared_error

# Define the Lasso model with a default alpha
model = Lasso(alpha=1.0)  # Adjust the alpha parameter as needed
model.fit(binary_train_data_features, train_data_label)

# Randomized Search for Lasso Regression
param_dist = {'alpha': np.logspace(-6, 6, 200)}
lasso_random = RandomizedSearchCV(Lasso(), param_distributions=param_dist, n_iter=50, scoring='neg_mean_squared_error', cv=5, random_state=42)
lasso_random.fit(binary_train_data_features, train_data_label)

# Best parameters from the randomized search
best_alpha = lasso_random.best_params_['alpha']
print(f"Best alpha from Randomized Search: {best_alpha}")

# Use the best alpha to fit the Lasso model
model = Lasso(alpha=best_alpha)
model.fit(binary_train_data_features, train_data_label)

# Predict on the test set
test_pred_log = model.predict(binary_test_data_features)

# Convert log predictions back to normal scale
test_pred = np.exp(test_pred_log)

# Creating submission DataFrame
submission = pd.DataFrame({
    'Id': test_data['Id'],  # Ensure this matches your test data ID column
    'SalePrice': test_pred
})

# Exporting the submission file
submission.to_csv('submission.csv', index=False)

# Evaluate the model (if you have development data to do so)
# rmsle = np.sqrt(mean_squared_error(dev_data_label, test_pred_log))
# print(f"Root Mean Squared Log Error (Lasso): {rmsle}")

from sklearn.ensemble import RandomForestRegressor

# Define the model
model = RandomForestRegressor(n_estimators=100)  # You can adjust the number of trees

# Fit the model
model.fit(binary_train_data_features, train_data_label)

# Predict on development data
test_pred_log = model.predict(binary_test_data_features)

# Convert log predictions back to normal scale
test_pred = np.exp(test_pred_log)

# Creating submission DataFrame
submission = pd.DataFrame({
    'Id': test_data['Id'],  # Ensure this matches your test data ID column
    'SalePrice': test_pred
})

# Exporting the submission file
submission.to_csv('random_forest_submission.csv', index=False)

from sklearn.linear_model import Lasso

# Define the model
model = Lasso(alpha=1.0)  # You can adjust the alpha parameter as needed

# Fit the model
model.fit(binary_train_data_features, train_data_label)

# Predict on development data
test_pred_log = model.predict(binary_test_data_features)

# Convert log predictions back to normal scale
test_pred = np.exp(test_pred_log)

# Creating submission DataFrame
submission = pd.DataFrame({
    'Id': test_data['Id'],  # Ensure this matches your test data ID column
    'SalePrice': test_pred
})

# Exporting the submission file
submission.to_csv('submission.csv', index=False)

# Fit the model
model = LinearRegression()
model.fit(binary_train_data_features, train_data_label)

# Predict on development data

test_pred_log = model.predict(binary_test_data_features)

# Convert log predictions back to normal scale
test_pred = np.exp(test_pred_log)

# Creating submission DataFrame
submission = pd.DataFrame({
    'Id': test_data['Id'],  # Ensure this matches your test data ID column
    'SalePrice': test_pred
})

# Exporting the submission file
submission.to_csv('submission.csv', index=False)